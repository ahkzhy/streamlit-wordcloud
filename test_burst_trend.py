import unittest
import pandas as pd
import numpy as np
from collections import deque
from datetime import datetime

# å‡è®¾ä½ çš„å‡½æ•°åœ¨ä¸€ä¸ªåä¸º frequency_utils çš„æ–‡ä»¶ä¸­
from frequency_utils import calculate_word_trends, detect_burst_words


# ========================================================
# æµ‹è¯•è¾…åŠ©ç±»ï¼šæ¨¡æ‹Ÿ HistoryDataQueue
# ========================================================
class MockHistoryQueue:
    """æ¨¡æ‹Ÿä½ çš„ HistoryDataQueue ç±»ï¼Œåªå®žçŽ° get_all ç”¨äºŽæµ‹è¯•"""
    def __init__(self, data_list):
        # data_list æ ¼å¼: [(timestamp, df), (timestamp, df), ...]
        self.data = data_list

    def get_all(self):
        return self.data

# ========================================================
# å•å…ƒæµ‹è¯•ç±»
# ========================================================
class TestTrendAnalysis(unittest.TestCase):

    def setUp(self):
        # print("\n--- Setting up test data ---")
        pass

    # ------------------------------------------------
    # æµ‹è¯• calculate_word_trends
    # ------------------------------------------------
    def test_calculate_word_trends(self):
        print("\nðŸ§ª Testing calculate_word_trends...")

        # 1. æž„é€ æ—§æ•°æ® (Round 1)
        old_data = pd.DataFrame({
            'word': ['apple', 'banana', 'common_word'],
            'frequency': [10, 5, 20]
        })

        # 2. æž„é€ æ–°æ•°æ® (Round 2)
        # - apple: æ¶ˆå¤± (Lost)
        # - banana: ä¾ç„¶å­˜åœ¨ (Common)
        # - common_word: é¢‘çŽ‡å˜å¤§ (Common)
        # - durian: æ–°å‡ºçŽ° (New)
        new_data = pd.DataFrame({
            'word': ['banana', 'common_word', 'durian'],
            'frequency': [5, 50, 15]
        })

        # 3. è¿è¡Œå‡½æ•°
        result = calculate_word_trends(old_data, new_data)

        # 4. éªŒè¯ 'new' (New words)
        new_df = result['new']
        print(f"  [New Words]: found {len(new_df)}")
        self.assertEqual(len(new_df), 1)
        self.assertEqual(new_df.iloc[0]['word'], 'durian')
        self.assertEqual(new_df.iloc[0]['trend'], 'new')

        # 5. éªŒè¯ 'lost' (Lost words)
        lost_df = result['lost']
        print(f"  [Lost Words]: found {len(lost_df)}")
        self.assertEqual(len(lost_df), 1)
        self.assertEqual(lost_df.iloc[0]['word'], 'apple')
        self.assertEqual(lost_df.iloc[0]['trend'], 'lost')

        # 6. éªŒè¯ 'common' (Common words)
        common_df = result['common']
        print(f"  [Common Words]: found {len(common_df)}")
        self.assertEqual(len(common_df), 2) # banana, common_word
        
        # éªŒè¯ growth rate calculation
        # common_word: old=20, new=50 -> change=30 -> rate=1.5
        word_row = common_df[common_df['word'] == 'common_word'].iloc[0]
        self.assertAlmostEqual(word_row['freq_change_rate'], 1.5)
        print("  âœ… calculate_word_trends Passed!")

    # ------------------------------------------------
    # æµ‹è¯• detect_burst_words
    # ------------------------------------------------
    def test_detect_burst_words(self):
        print("\nðŸ§ª Testing detect_burst_words...")

        # é…ç½®çª—å£å‚æ•°
        BASELINE_LEN = 8
        CURRENT_LEN = 2
        TOTAL_LEN = BASELINE_LEN + CURRENT_LEN

        # æž„é€ è™šæ‹Ÿæ•°æ®æµ
        # æˆ‘ä»¬è®¾è®¡ä¸€ä¸ªè¯ "SuperTopic"ï¼Œåœ¨åŸºçº¿æœŸå¾ˆä½Žï¼Œåœ¨å½“å‰çª—å£çªç„¶çˆ†å‘
        # æˆ‘ä»¬è®¾è®¡ä¸€ä¸ªè¯ "NormalTopic"ï¼Œä¸€ç›´å¾ˆå¹³ç¨³
        
        history_data = []

        # --- Phase 1: Baseline (å‰8æ¬¡æ›´æ–°) ---
        for i in range(BASELINE_LEN):
            df = pd.DataFrame({
                'word': ['SuperTopic', 'NormalTopic', 'Noise'],
                'frequency': [1, 10, 1] # SuperTopic å¹³å‡ä¸º 1
            })
            history_data.append((datetime.now(), df))

        # --- Phase 2: Current (åŽ2æ¬¡æ›´æ–°) ---
        for i in range(CURRENT_LEN):
            df = pd.DataFrame({
                'word': ['SuperTopic', 'NormalTopic', 'Noise'],
                'frequency': [50, 10, 1] # SuperTopic çªç„¶å˜æˆ 50
            })
            history_data.append((datetime.now(), df))

        # åˆ›å»º Mock é˜Ÿåˆ—
        mock_queue = MockHistoryQueue(history_data)

        # è¿è¡Œå‡½æ•°
        burst_df = detect_burst_words(
            mock_queue, 
            current_window_size=CURRENT_LEN, 
            baseline_window_size=BASELINE_LEN,
            min_freq_now=5,  # è¿‡æ»¤æŽ‰ Noise
            min_freq_base=0.5
        )

        print("  [Burst Result Table]:")
        print(burst_df.to_string())

        # éªŒè¯é€»è¾‘
        # 1. NormalTopic ä¸åº”è¯¥å‡ºçŽ°åœ¨ç»“æžœé‡Œï¼Œæˆ–è€… fold_change æŽ¥è¿‘ 1
        # å¦‚æžœå®ƒæ²¡å‡ºçŽ°ï¼ˆå› ä¸º min_freq_base æˆ–æŽ’åºï¼‰ï¼Œé‚£ä¹Ÿæ²¡äº‹ã€‚ä½†å¦‚æžœå‡ºçŽ°äº†ï¼Œfold_change åº”è¯¥æ˜¯ 1.0
        if 'NormalTopic' in burst_df['word'].values:
            row = burst_df[burst_df['word'] == 'NormalTopic'].iloc[0]
            self.assertAlmostEqual(row['fold_change'], 1.0, delta=0.2)

        # 2. SuperTopic åº”è¯¥æ˜¯çªå‘è¯
        # è®¡ç®—é¢„æœŸå€¼ï¼š
        # Baseline Total (8 frames) = 1 * 8 = 8. Window Ratio = 8/2 = 4.
        # Baseline Normalized = 8 / 4 = 2.0
        # Current Total (2 frames) = 50 + 50 = 100.
        # Fold Change = 100 / 2.0 = 50.0 (approx)
        
        target_row = burst_df[burst_df['word'] == 'SuperTopic']
        self.assertFalse(target_row.empty, "SuperTopic missed!")
        
        fold_change = target_row.iloc[0]['fold_change']
        freq_base = target_row.iloc[0]['freq_base']
        
        print(f"  [Verification] SuperTopic FoldChange: {fold_change} (Expected ~50.0)")
        
        self.assertAlmostEqual(freq_base, 2.0, delta=0.1)
        self.assertTrue(fold_change > 40, "Fold change should be huge")
        
        print("  âœ… detect_burst_words Passed!")

if __name__ == '__main__':
    unittest.main()